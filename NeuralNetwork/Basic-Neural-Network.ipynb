{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5j72wZl4Hw0",
        "outputId": "143b9563-381e-4fcc-f4f4-5d697b9a5075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "-b0w6aN64PXU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Create a seed for the random number generator\n",
        "        np.random.seed(1)\n",
        "        # Set synaptic weights to a 3 x 1 matrix, with values from -1 to 1 and a mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        \"\"\"\n",
        "        Takes the total of the inputs and normalizes them using a sigmoid function between 0 and 1.\n",
        "        \"\"\"\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, y):\n",
        "        \"\"\"\n",
        "        The sigmoid function's derivative is used to determine the appropriate weight modifications.\n",
        "        \"\"\"\n",
        "        return y * (1 - y)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \"\"\"\n",
        "Â        Modifying the synaptic weights as needed to improve the outcome.\n",
        "        \"\"\"\n",
        "        for iteration in range(training_iterations):\n",
        "            # Through the neural network, pass the training set.\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            # Calculate the error rate\n",
        "            err = training_outputs - output\n",
        "\n",
        "            # Multiply the error by the input and the sigmoid function's gradient. Less confident weights are changed more due to the function's nature.\n",
        "            adjustments = np.dot(training_inputs.T, err * self.sigmoid_derivative(output))\n",
        "\n",
        "            # Adjusting synaptic weights\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        \"\"\"\n",
        "        Pass inputs through the neural network to get output\n",
        "        \"\"\"\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
        "        return output"
      ],
      "metadata": {
        "id": "ndjfRfsx4SAv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Create a single neuron neural network and set it up.\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Random starting synaptic weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    # The training set has four instances, each having three input values and one output value.\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    # Train the neural network\n",
        "    neural_network.train(training_inputs, training_outputs, 10000)\n",
        "\n",
        "    print(\"Synaptic weights after training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    J = str(input(\"Input 1: \"))\n",
        "    K = str(input(\"Input 2: \"))\n",
        "    L = str(input(\"Input 3: \"))\n",
        "    \n",
        "    print(\"New situation: input data = \", J, K, L)\n",
        "    print(\"Output data: \")\n",
        "    print(neural_network.think(np.array([J, K, L])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb0gvvY45RvU",
        "outputId": "28699e1b-13e8-43d3-9d78-169fea618cb4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random starting synaptic weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Synaptic weights after training: \n",
            "[[ 9.67299303]\n",
            " [-0.2078435 ]\n",
            " [-4.62963669]]\n",
            "Input 1: 1\n",
            "Input 2: 2\n",
            "Input 3: 3\n",
            "New situation: input data =  1 2 3\n",
            "Output data: \n",
            "[0.00964519]\n"
          ]
        }
      ]
    }
  ]
}